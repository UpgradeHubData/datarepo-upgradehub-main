{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Validación de modelos.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Validación de modelos\n",
        "\n",
        "A la hora de crear nuestros modelos es importante que podamos validar los resultados que nos están proporcionando y así tener una idea clara de la fiabilidad de dichos modelos. \n",
        "\n",
        "En este notebook vamos a explorar algunas de las técnicas de validación de modelos que podemos utilizar. \n",
        "\n",
        "## Validación simple\n",
        "\n",
        "Es el método más sencillo de validación que consiste en repartir aleatoriamente las observaciones en dos grupos, el set de entrenamiento y el set de pruebas. \n",
        "\n",
        "Es una forma de validación fácil y rápida de implementar gracias a la funcionalidad de train_test_split que nos ofrece la libreria de scikit-learn pero tenemos que ser conscientes de que tiene dos problemas: \n",
        "- La estimación del error es variable dependiendo de qué observaciones se incluyan en el set de entrenamiento y el set de pruebas. Podemos minimizar este impacto fijando la semilla de los números pseudoaleatorios que utilizamos para la separación de los sets de entrenamiento y pruebas. \n",
        "- Al excluir parte de los datos del entrenamiento del modelo y dejarlos reservados para las pruebas, disminuimos la información disponible para el modelo y por lo tanto su capacidad predictiva. Podemos minimizar este impacto asegurándonos de tener un set de datos amplio y que refleje los distintos comportamientos de los datos y así no mermar la capacidad predictiva del modelo. \n",
        "\n"
      ],
      "metadata": {
        "id": "SM288XTIE2Wo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a ver un ejemplo de como empleamos el método de validación simple. "
      ],
      "metadata": {
        "id": "Qte-_MFfPumQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yi3xOE-dExf1"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a crear un set de datos que utilizaremos en todos los ejemplos para comparar su eficacia\n",
        "X, y = make_blobs(n_samples=500,random_state =123)"
      ],
      "metadata": {
        "id": "Vq1nFDdjQN0d"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vamos a crear nuestro set de entrenamiento y de test \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)"
      ],
      "metadata": {
        "id": "8tkP71gEQkfX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el modelo que vamos a utilizar con todos los métodos de validación para poder compararlo\n",
        "# En este caso será un clasificador utilizando un Random Forest\n",
        "\n",
        "rf = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "AVxDC1e_Qx_J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Entrenamos el modelo con los datos del set de entrenamiento\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQDznAE5RDQJ",
        "outputId": "af0aa664-ef1f-4e67-9a21-9f745ab282a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generamos predicciones para el set de pruebas\n",
        "y_pred = rf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "yq7C0QajRJ2q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finalmente calculamos la precisión para el modelo\n",
        "precision_rf = accuracy_score(y_test, y_pred)\n",
        "print(\"Precision validación simple: %.3f\" % precision_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vw1JDnYRTZR",
        "outputId": "ff2a1db3-77c6-4fe6-964b-821f16a83ec1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision validación simple: 0.944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leave One Out Cross-Validation (LOOCV)\n",
        "\n",
        "El método LOOCV es un método iterativo que se inicia empleando como set de entrenamiento todas las observaciones disponibles en nuestro set de datos menos una, que se excluye para emplearla como validación. \n",
        "\n",
        "Si se emplea una única observación para calcular el error del modelo, este varía mucho dependiendo de qué observación se haya seleccionado. Para evitarlo, el proceso se repite tantas veces como observaciones disponibles, excluyendo en cada iteración una observación distinta, entrenando el modelo con el resto y calculando el error con dicha observación. Finalmente, el error estimado por el método LOOCV es el promedio de todos los errores calculados durante la iteración del proceso. \n",
        "\n",
        "Este método LOOCV permite reducir la variabilidad que se origina si se divide aleatoriamente las observaciones en dos grupos. Esto es así porque al final del proceso de LOOCV se acaban empleando todos los datos disponibles tanto para entrenamiento como para validación. Al no haber una separación aleatoriade los datos, los resultados de LOOCV son reproducibles. \n",
        "\n",
        "La principal desventaja de este método es su coste computacional. El proceso requiere que el modelo sea reajustado y validado tantas veces como observaciones disponibles, lo que en algunos casos puede ser muy complicado. \n",
        "\n",
        "LOOCV es un proceso de validación muy extendido ya que puede aplicarse para evaluar cualquier tipo de modelo. Sin embargo, hay distintos autores de publicaciones sobre estadística que consideran que, al emplearse todas las observaciones como entrenamiento, se puede estar cayendo en el overfitting y, aunque lo consideran un método aceptable, aconsejan utilizar otros métodos como K-Fold Cross-Validation (KFCV)\n",
        "\n"
      ],
      "metadata": {
        "id": "hGaDFbSkPsmr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a ver cómo hacemos la validación LOOCV en python con el mismo ejemplo que hemos utilizado en el método de validación simple:"
      ],
      "metadata": {
        "id": "jWiLuifORyN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeaveOneOut"
      ],
      "metadata": {
        "id": "RLrXfKiNPtOC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el objeto que nos permite hacer la separación de los datos\n",
        "cv = LeaveOneOut()"
      ],
      "metadata": {
        "id": "oY6BCOOoR8eL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Necesitamos guardar tanto los valores reales como las predicciones en cada iteración \n",
        "# así que creamos dos listas para esas tareas\n",
        "\n",
        "y_true_loocv, y_pred_loocv = list(), list()"
      ],
      "metadata": {
        "id": "0njGQj9MSJVm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Empezamos el proceso iterativo de validación del modelo utilizando el mismo tipo de modelo que en el \n",
        "# ejemplo de validación simple\n",
        "\n",
        "for train_ix, test_ix in cv.split(X):\n",
        "  # hacemos la separación de los sets de entrenamiento y pruebas\n",
        "  X_train, X_test = X[train_ix, :], X[test_ix, :]\n",
        "  y_train, y_test = y[train_ix], y[test_ix]\n",
        "  # Entrenamos el modelo\n",
        "  modelo = RandomForestClassifier()\n",
        "  modelo.fit(X_train, y_train)\n",
        "  # generamos predicciones\n",
        "  y_hat = modelo.predict(X_test)\n",
        "  # guardamos el valor real y la predicción para su evaluación más adelante\n",
        "  y_true_loocv.append(y_test[0])\n",
        "  y_pred_loocv.append(y_hat[0])"
      ],
      "metadata": {
        "id": "v6NYLuSWSY-Q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finalmente calculamos la precisión del modelo con este tipo de validación\n",
        "precision_loocv = accuracy_score(y_true_loocv, y_pred_loocv)\n",
        "\n",
        "print(\"Precision validacion LOOCV: %.3f\" % precision_loocv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMbi91GwTPNK",
        "outputId": "4725bc1e-d822-4bb8-bba1-03a06f2a09f3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision validacion LOOCV: 0.950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Fold Cross Validation (KFCV)\n",
        "\n",
        "El método K-Fold Cross Validation (KFCV) es al igual que LOOCV un método iterativo de validación de modelos. \n",
        "\n",
        "Consiste en dividir los datos de forma aleatoria en *k* grupos de aproximadamente el mismo tamaño, donde *k-1* grupos se emplean para entrenar el modelo y uno de los grupos se emplea como validación. Este proceso se repite durante *k* veces utilizando un grupo distinto como validación en cada iteración. El proceso genera *k* estimaciones del error y el error final se calcula como la media de las distintas medidas de error durante el proceso iterativo. \n",
        "\n",
        "KFCV presenta dos ventajas frente a LOOCV: \n",
        "\n",
        "- Es menos intenso computacionalmente, dado que el número de iteraciones necesarias viene determinado por el valor *k* escogido. Por lo general, se recomienda utilizar un valor de *k* entre 5 y 10. \n",
        "\n",
        "- Gestiona mejor el balance entre bias y varianza. La principal ventaja de KFCV es que consigue una estimación precisa del error de test gracias a un mejor balance entre bias y varianza. LOOCV emplea *n-1* observaciones para entrenar el modelo, lo que es prácticamente todo el set de datos disponible, maximizando así el ajuste del modelo a los datos disponibles y reduciendo el bias. Sin embargo, para la estimación final del error se promedian las estimaciones de *n* modelos entrenados prácticamente con los mismos datos (solo hay una observación de diferencia entre cada set de entrenamiento), por lo que están altamente correlados. Eso se traduce en un mayor riesgo de overfitting. En el método KFCV los *k* grupos empleados como set de entrenamiento se solapan mucho menos, lo que se traduce en un riesgo mucho menor de caer en el overfitting a pesar de utilizar todos los datos disponibles para entrenar el modelo. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xbPvtc-qRqj0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a ver un ejemplo de aplicación de KFCV sobre el mismo set de datos que hemos utilizado antes"
      ],
      "metadata": {
        "id": "7ZZ7Hw_WT2T1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import mean"
      ],
      "metadata": {
        "id": "HiWWixw_RrPN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparamos el objeto que nos va a permitir separar los datos en los distintos grupos\n",
        "\n",
        "cv = KFold( n_splits=10, random_state = 123, shuffle=True)"
      ],
      "metadata": {
        "id": "SkHJH46RUIIE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el modelo que vamos a utilizar, seguimos con el clasificador de RandomForest\n",
        "rf_kfcv = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "y4-xoAnxUYw5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# El método de cross_val_score nos permite entrenar y validar el modelo directamente\n",
        "medidas = cross_val_score(rf_kfcv, X, y, scoring='accuracy', cv=cv)"
      ],
      "metadata": {
        "id": "_uNjhaW1Ui3b"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision_kfcv = mean(medidas)\n",
        "\n",
        "print(\"Precision KFCV: %.3f\" % precision_kfcv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OB-TL7GU270",
        "outputId": "e1dde8fc-a031-4360-fc17-464d8f1677c1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision KFCV: 0.942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparación de métodos de validación\n",
        "\n",
        "En general no existe un método de validación que supere al resto en todos los escenarios, y la elección debe basarse en diversos factores: \n",
        "\n",
        "- Si el tamaño de la muestra es pequeño, se recomienda utilizar KFCV ya que consigue un buen equilibrio entre bias y varianza. \n",
        "\n",
        "- Si el tamaño de la muestra es muy grande, la diferencia entre los distintos métodos se reduce mucho y se debe valorar la eficiencia computacional. KFCV con k=5 o una validación simple son suficientes para obtener buenas estimaciones de las métricas del modelo. \n"
      ],
      "metadata": {
        "id": "PnlhfZUYToar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qOVVKLlRXAtJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}