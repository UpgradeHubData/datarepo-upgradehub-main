{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature engineering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Feature engineering\n",
        "\n",
        "En esta sección vamos a ver un conjunto de técnicas que podemos aplicar a nuestros datos para prepararlos y transformarlos para poder ser utilizados por nuestros modelos más adelante. \n",
        "\n",
        "Para que nuestros modelos funcionen bien sobre nuevos datos, a veces es necesario diseñar nuevas variables de entrada basadas en las que ya disponemos para poder mejorar la capacidad predictiva de nuestros modelos. \n"
      ],
      "metadata": {
        "id": "-snAFqIdPVfu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a ver un ejemplo muy sencillo para visualizar lo que queremos decir a la hora de diseñar nuevas variables de entrada. \n",
        "\n",
        "En la siguiente tabla vemos los precios de casas en una determinada ciudad. La tabla contiene la superficie de las casas y el precio de la casa\n",
        "\n",
        "| Superficie (m2) | Precio |\n",
        "|------------|--------|\n",
        "| 240        | 90000  |\n",
        "| 320        | 150000 |\n",
        "| 250        | 100000 |\n",
        "| 210        | 120000 |\n",
        "| 250        | 135000 |\n",
        "\n",
        "\n",
        "Podemos añadir una nueva columna que nos muestre el precio por metro cuadrado. \n",
        "\n",
        "| Superficie (m2) | Precio | Precio por m2 |\n",
        "|-----------------|--------|---------------|\n",
        "| 240             | 90000  | 375           |\n",
        "| 320             | 150000 | 468,75        |\n",
        "| 250             | 100000 | 400           |\n",
        "| 210             | 120000 | 571,43        |\n",
        "| 250             | 135000 | 540           |\n",
        "\n",
        "Este es un ejemplo muy básico de feature engineering puesto que hemos creado una nueva variable de entrada en nuestro set de datos que nos permite pasarle más información a nuestro modelo y conseguir que tenga un mejor desempeño. "
      ],
      "metadata": {
        "id": "vDQAJwlkQ1Ic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Técnicas para feature engineering\n",
        "\n",
        "Vamos a ver algunas de las técnicas que podemos aplicar a nuestros datos para transformarlos y añadir valor que haga que las predicciones de nuestro modelo sean mejores. Hay que tener en cuenta que no hay una única forma de hacer feature engineering y cada set de datos requiere unas transformaciones diferentes, por lo que esto debe ser tomado como una introducción a estas técnicas y queda en manos del alumno identificar cuáles son las que se debe aplicar en cada momento."
      ],
      "metadata": {
        "id": "n-WAncHmbXZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imputación \n",
        "Se trata de rellenar aquellos valores que se encuentran vacíos. Estos valores vacíos pueden deberse a errores humanos a la hora de registrar los datos, interrupciones en la transmisión de datos, datos que se han eliminado para mantener la privacidad etc... \n",
        "Estos valores vacíos afectan negativamente al desempeño de los modelos y debemos tratarlos para evitar su impacto. \n",
        "\n",
        "Hay dos formas de imputación: \n",
        "- **Imputación numérica**: Rellenamos los valores que se han quedado vacíos en variables numéricas. Se pueden rellenar estos valores vacíos con un valor en concreto si tenemos un contexto que nos permita decidir cuál es ese valor o bien con el valor medio de la variable. \n",
        "\n",
        "- **Imputación categórica**: Rellenamos los valores que se han quedado vacíos en variables categóricas. Se puede rellenar con el valor más repetido de esa categoría o si tenemos información sobre la distribución de los valores de la variable podemos escoger el valor que mejor le venga a esos valores vacíos. \n",
        "\n",
        "### Identificar y tratar valores extremos (outliers)\n",
        "\n",
        "Los valores extremos (outliers) suelen afectar de forma negativa al desempeño de los modelos de machine learning. Por eso es muy importante identificarlos con el análisis de EDA y tratarlos. Hay varias estrategias para tratar los valores extremos (outliers):\n",
        "- **Borrar los valores extremos (outliers)**: Si los valores extremos se encuentran concentrados en unas pocas variables, podemos borrar esos registros para evitar el impacto que pueden tener en el desempeño del modelo. Si los valores extremos se encuentran en varias variables de nuestros datos esta estrategia puede llevarnos a borrar una cantidad significativa de datos y no ser la más adecuada. \n",
        "- **Reemplazar sus valores**: Podemos tratar los valores extremos (outliers) como valores vacíos y aplicar las estrategias de imputación que hemos visto en la sección anterior\n",
        "- **Poner un límite**: Si tenemos contexto que nos permita reemplazar los valores extremos (outliers) por un límite que consideramos que es el valor máximo que pueden asumir nuestros datos. \n",
        "\n",
        "### Cambiar a una escala logarítmica\n",
        "Una estrategia muy utilizada en situaciones donde los datos presentan grandes variaciones es aplicar un logaritmo sobre los datos y reemplazar el valor original por el valor logarítmico. Esto nos permite transformar variables con grandes variaciones a variables con una distribución cercana a normal. \n",
        "\n",
        "### One-hot encoding\n",
        "Es una técnica que podemos utilizar para transformar nuestras variables categóricas en variables numéricas. Al aplicar one-hot encoding sobre una variable categórica identificamos los valores distintos que tiene la variable categórica y creamos nuevas columnas para esos valores de la variable categórica. Estas nuevas columnas tendrán un 1 si el valor de la variable categórica original coincide con el valor de la columna y 0 en caso contrario. Vamos a ver un ejemplo: \n",
        "\n",
        "Tenemos la siguiente variable categórica: \n",
        "\n",
        "| Animales |\n",
        "|----------|\n",
        "| Perro    |\n",
        "| Gato     |\n",
        "| Pez      |\n",
        "| Perro    |\n",
        "| Pez      |\n",
        "| Gato     |\n",
        "\n",
        "Al aplicar la estrategia de one-hot encoding, acabamos con estas nuevas columnas:\n",
        "\n",
        "| Animales | Perro | Gato | Pez |\n",
        "|----------|-------|------|-----|\n",
        "| Perro    | 1     | 0    | 0   |\n",
        "| Gato     | 0     | 1    | 0   |\n",
        "| Pez      | 0     | 0    | 1   |\n",
        "| Perro    | 1     | 0    | 0   |\n",
        "| Pez      | 0     | 0    | 1   |\n",
        "| Gato     | 0     | 1    | 0   |\n",
        "\n",
        "\n",
        "### Escalado de las variables\n",
        "\n",
        "El escalado de las variables numéricas es una de las transformaciones más importantes para algunos de los modelos de machine learning para que su funcionamiento sea el esperado, especialmente aquellos que se basan en calcular distancias entre nuestros datos. \n",
        "\n",
        "Hay dos estrategias muy comunes para escalar nuestras variables numéricas:\n",
        "\n",
        "- **Normalización**: Se escalan todos los valores para tener acabar en un rango entre 0 y 1. Este escalado no influye en la distribución de las variables pero destaca mucho el efecto de los valores extremos (outliers), por lo que se recomienda tratar los valores extremos (outliers) antes de aplicar el escalado con normalización. \n",
        "\n",
        "- **Estandarización**: El proceso de estandarización es un proceso de escalado donde tenemos en cuenta la desviación típica de las variables. Si la desviación típica de las variables son diferentes,los rangos de las variables también serán diferentes. En este tipo de escalado el efecto de los valores extremos (outliers) es mucho más reducido al tener en cuenta la desviación típica de las variables. "
      ],
      "metadata": {
        "id": "wE76WthAb-7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crear y utilizar Pipelines\n",
        "\n",
        "Los pipelines son estructuras que nos ofrecen la oportunidad de repetir fácilmente los pasos que apliquemos a nuestros datos del set de entrenamiento a los datos del set de pruebas. Esto es muy importante porque cualquier transformación que hagamos en los datos de entrenamiento del modelo tenemos que aplicarlos a los datos del set de pruebas para que sean comparables y así evitar que el modelo nos de resultados erroneos. Dado que las transformaciones que hacemos en el set de datos de entrenamiento se hacen al principio de nuestro trabajo con el modelo y el set de pruebas se utiliza una vez hemos hecho el entrenamiento del modelo, podemos olvidarnos de alguna de las transformaciones que tenemos que aplicar a nuestros datos del set de pruebas y tardar bastante en encontrar la razón por la que los resultados del modelo para los datos del set de pruebas son tan diferentes de los resultados del set de entrenamiento. \n",
        "\n",
        "Para evitar estas situaciones, es una buena práctica utilizar los pipelines que nos permiten definir las transformaciones que queremos aplicar a nuestros datos y luego aplicarlas tanto a los datos de entrenamiento como a los de pruebas. \n",
        "\n",
        "La libreria scikit-learn nos ofrece unos objetos de tipo Pipeline que nos permite ir definiendo las transformaciones que queremos aplicar a nuestros datos y el modelo que vamos a crear y aplicar dichas transformaciones a sets de datos y utilizar el modelo de forma muy fácil. \n",
        "\n",
        "\n",
        "Los objetos pipeline que nos ofrece la libreria scikit-learn tienen la siguiente estructura:\n",
        "\n",
        "\n",
        "\n",
        "```puython\n",
        "Pipeline(steps=[('nombre_del_preprocesamiento', preprocessor),\n",
        "                ('nombre_del_modelo', ml_model())])\n",
        "```\n",
        "\n",
        "Por lo tanto debemos definir el preprocesamiento que queremos aplicar y el modelo que vamos a aplicar en nuestro pipeline.\n",
        "\n",
        "\n",
        "\n",
        "Vamos a ver un ejemplo:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NZGQyn74Pnog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "yTfB5lVzUbeg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos unos datos que vamos a utilizar para demostrar el valor de los pipelines\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/MicrosoftDocs/ml-basics/master/data/daily-bike-share.csv')"
      ],
      "metadata": {
        "id": "MPCumCyoURfn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vamos a ver los tipos de datos que tenemos en las distintas variables\n",
        "data.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPYWTfXDUhxP",
        "outputId": "a69c6a58-0b8e-4673-b110-7f37900d2a46"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "instant         int64\n",
              "dteday         object\n",
              "season          int64\n",
              "yr              int64\n",
              "mnth            int64\n",
              "holiday         int64\n",
              "weekday         int64\n",
              "workingday      int64\n",
              "weathersit      int64\n",
              "temp          float64\n",
              "atemp         float64\n",
              "hum           float64\n",
              "windspeed     float64\n",
              "rentals         int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vamos a ver si hay algún valor vacío\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIGl-NFJU6aD",
        "outputId": "70ecf7cf-4625-414a-b891-dc9bda677559"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "instant       0\n",
              "dteday        0\n",
              "season        0\n",
              "yr            0\n",
              "mnth          0\n",
              "holiday       0\n",
              "weekday       0\n",
              "workingday    0\n",
              "weathersit    0\n",
              "temp          0\n",
              "atemp         0\n",
              "hum           0\n",
              "windspeed     0\n",
              "rentals       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "h9KUPAhAYYE6",
        "outputId": "5f647c5d-befe-4bf4-dff9-5689079ea29a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   instant    dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
              "0        1  1/1/2011       1   0     1        0        6           0   \n",
              "1        2  1/2/2011       1   0     1        0        0           0   \n",
              "2        3  1/3/2011       1   0     1        0        1           1   \n",
              "3        4  1/4/2011       1   0     1        0        2           1   \n",
              "4        5  1/5/2011       1   0     1        0        3           1   \n",
              "\n",
              "   weathersit      temp     atemp       hum  windspeed  rentals  \n",
              "0           2  0.344167  0.363625  0.805833   0.160446      331  \n",
              "1           2  0.363478  0.353739  0.696087   0.248539      131  \n",
              "2           1  0.196364  0.189405  0.437273   0.248309      120  \n",
              "3           1  0.200000  0.212122  0.590435   0.160296      108  \n",
              "4           1  0.226957  0.229270  0.436957   0.186900       82  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2bcf9832-cb61-41af-a6b2-d57c678cf513\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instant</th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>rentals</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1/1/2011</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.344167</td>\n",
              "      <td>0.363625</td>\n",
              "      <td>0.805833</td>\n",
              "      <td>0.160446</td>\n",
              "      <td>331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1/2/2011</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.363478</td>\n",
              "      <td>0.353739</td>\n",
              "      <td>0.696087</td>\n",
              "      <td>0.248539</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1/3/2011</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.196364</td>\n",
              "      <td>0.189405</td>\n",
              "      <td>0.437273</td>\n",
              "      <td>0.248309</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1/4/2011</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.212122</td>\n",
              "      <td>0.590435</td>\n",
              "      <td>0.160296</td>\n",
              "      <td>108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1/5/2011</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.226957</td>\n",
              "      <td>0.229270</td>\n",
              "      <td>0.436957</td>\n",
              "      <td>0.186900</td>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bcf9832-cb61-41af-a6b2-d57c678cf513')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2bcf9832-cb61-41af-a6b2-d57c678cf513 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2bcf9832-cb61-41af-a6b2-d57c678cf513');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No hay ninguna variable que tenga valores vacíos en este data set pero tenemos que ocuparnos de las variables que son categóricas para poder transformarlas antes de meterlas en nuestro modelo. "
      ],
      "metadata": {
        "id": "q_tcY_XrVHo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a quedarnos con las columnas más interesantes\n",
        "data = data[['season', 'mnth','holiday', 'weekday','workingday', 'weathersit','temp','atemp','hum', 'windspeed', 'rentals']]"
      ],
      "metadata": {
        "id": "nIR2Vbz1Yhbp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Antes de empezar a crear nuestro pipeline, vamos a crear los sets de entrenamiento y de pruebas\n",
        "X = data.drop('rentals', axis=1)\n",
        "y = data['rentals']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
      ],
      "metadata": {
        "id": "17PqzfykVF-b"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Como hemos visto para poder crear nuestro pipeline tenemos que definir el preprocesamiento que queremos aplicar a nuestros datos\n",
        "# Vamos a definir los pasos que queremos seguir para las variables numéricas y para las variables categóricas \n",
        "\n",
        "# Para las variables numéricas vamos a aplicar un SimpleInputer que rellene los valores vacíos con la media de los valores de esa variable\n",
        "# y luego vamos a escalar la variable utilizando un StandardScaler\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')), \n",
        "                                      ('scaler', StandardScaler())])\n",
        "\n",
        "# Para las variables categóricas vamos a aplicar un SimpleInputer que rellene los valores vacíos con un valor constante\n",
        "# y luego vamos a utilizar un OrdinalEncoder para transformar esas variables categóricas en numéricas\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant')), \n",
        "                                          ('encoder', OrdinalEncoder())])"
      ],
      "metadata": {
        "id": "ccXXp2ldVFez"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ahora vamos a definir el grupo de variables a las que vamos a aplicar el preprocesamiento numérico y el grupo de variables que va recibir el preprocesamiento categórico\n",
        "\n",
        "variables_numericas = ['temp','atemp','hum','windspeed']\n",
        "variables_categoricas = ['season', 'mnth', 'holiday', 'weekday','workingday','weathersit']\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[('numerico', numeric_transformer, variables_numericas), \n",
        "                                               ('categorico',categorical_transformer, variables_categoricas)])"
      ],
      "metadata": {
        "id": "acmJ6IBGY2kl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ahora que tenemos definido el preprocesamiento que queremos hacer a nuestros datos, vamos a definir el modelo que queremos utilizar con nuestro pipeline\n",
        "# En este caso vamos a utilizar un Random Forest. No te preocupes, porque veremos cómo funcionan más adelante\n",
        "\n",
        "pipeline = Pipeline(steps=[('preprocesamiento', preprocessor),\n",
        "                           ('modelo', RandomForestRegressor())])"
      ],
      "metadata": {
        "id": "KgYCHWjQZsJx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hasta ahora solamente hemos estado definiendo los pasos que queremos aplicar a nuestros datos\n",
        "# vamos a utilizar el pipeline utilizando el método fit que ofrecen todos los modelos de la libreria scikit-learn\n",
        "\n",
        "rf_model = pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "k9DpGnUhaayv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Podemos aplicar las transformaciones y generar predicciones utilizando el método predict del pipeline\n",
        "predictions = pipeline.predict(X_test)\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gL8R1q7oa_HX",
        "outputId": "6b6a4707-b972-4f4c-d218-606716626733"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 711.98,  535.76,  662.52,  350.71, 1018.92, 1980.71,  496.59,\n",
              "        770.69,  904.62,  301.3 ,  613.65, 1484.9 , 2512.31, 1212.4 ,\n",
              "        303.65,  884.42, 1317.48, 2179.43,  776.57,  634.47, 2442.55,\n",
              "       2136.05,   52.75,  893.96,  778.24,  224.87,  750.63,   64.76,\n",
              "        783.72,  576.08, 1171.99,  710.03, 1168.16, 1157.08, 1236.06,\n",
              "       1073.16,  894.1 ,  724.72,  723.23,  224.78,  770.79,   95.64,\n",
              "        289.82,  592.65,  547.03,  678.88,  757.31,  846.64,  270.41,\n",
              "        138.13,  491.79,  335.17,  828.18,  355.53,  725.04,  792.34,\n",
              "       1322.71,  832.68,  775.14, 1128.1 ,  999.33,  195.86,  667.39,\n",
              "       2036.22, 1482.3 ,  135.04,   61.78,  483.8 ,  325.4 , 1790.12,\n",
              "        717.64,  313.79,  929.4 ,  802.47,  126.69,  696.36,  142.75,\n",
              "        495.85, 1175.44,  254.35,  598.1 ,  698.21,  775.  ,  795.94,\n",
              "       1288.95,  856.93,  301.44, 1136.96, 1033.22,  214.84,  886.8 ,\n",
              "       2233.42,  566.37,  486.19,  377.01, 2232.41,  246.96,  740.2 ,\n",
              "        678.27,  555.6 ,  519.4 , 1145.58,  304.1 , 2571.05,  549.  ,\n",
              "        288.5 ,  299.29,  493.85,   63.05,  624.32,  907.12, 2088.91,\n",
              "        773.45,  873.05,  197.  ,  344.1 ,  460.45,  834.18,  461.4 ,\n",
              "        191.2 ,  184.89, 1056.45, 1106.01,  916.72, 1485.4 , 2331.39,\n",
              "        772.1 ,  648.83,  933.91, 1265.37,  843.62,  797.85, 2157.06,\n",
              "        325.71,  588.21,  638.65, 1614.7 ,  950.64, 1788.42, 1485.79,\n",
              "        236.36, 2404.57, 2337.34,  959.72,  833.5 , 1183.71,  797.54])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}