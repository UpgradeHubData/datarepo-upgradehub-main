{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optimización de hiperparámetros.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Optimización de hiperparámetros\n"
      ],
      "metadata": {
        "id": "vgubb0WPmLrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los hiperparámetros son piezas claves en los modelos de machine learning que nos permiten afinar el desempeño de dichos modelos y ajustarlos a los problemas que queremos resolver. \n",
        "\n",
        "Por lo tanto, ser capaces de optimizar sus valores y encontrar la mejor combinación de valores para los hiperparámetros de nuestros modelos es una tarea clave para poder maximizar el rendimiento que obtengamos con nuestros modelos. \n",
        "\n",
        "Necesitamos conocer, hasta cierto punto, la implicación que tiene cada hiperparámetro en cada modelo y sus posible valores. Entender en profundidad el significados y los posibles valores que pueden tener cada hiperparámetro de cada modelo nos permite obtener los mejores resultados de los modelos con los que vamos a trabajar, pero este módulo del bootcamp no espera llegar tan profundamente y eso es materia de estudio para otros cursos más especializados. En este módulo vamos a ver algunas de las técnicas más utilizadas para la optimización de los hiperparámetros de los modelos con los que vamos a trabajar. \n",
        "\n",
        "La opción de poder ir modificando manualmente los valores de los hiperparámetros de nuestros modelos y comparar los resultados que nos ofrecen existe, pero es evidente que un ajuste de este tipo suele llevar mucho tiempo, no siempre se realiza de forma rigurosa y dificulta inmensamente la sistematización de los resultados de nuestros modelos. \n",
        "\n",
        "Otra opción que tenemos disponible es aplicar técnicas automatizadas y sencillas como son **Grid Search** y **Random Search** que suelen obtener buenos resultados. A continuación iremos viendo las características de ambas técnicas, aunque ambas técnicas presentan un elevado coste de tiempo y recursos computacionales. \n",
        "\n",
        "Finalmente, podemos encontrar el valor optimo para nuestros hiperparámetros utilizando la técnica de **optimización bayesiana**. A pesar de que presenta una mayor dificultad de implementación, esta técncia nos permite obtener buenos resultados con un menor coste en tiempo y recursos computacionales. \n"
      ],
      "metadata": {
        "id": "GJrvud-qmPVi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GridSearch\n",
        "\n",
        "La técnica de GridSearch funciona probando todas las posibles combinaciones de parámetros que se desean probar en el modelo. Cada uno de esos parámetros se prueba en una serie de iteraciones de validación cruzada. Finalmente, el modelo que presente los mejores resultados es seleccionado y sus hiperparámetros son accesibles para que podamos utilizar dicho modelo y podamos evaluar cuáles han sido los mejores hiperparámetros que podemos utilizar con nuestro modelo. \n",
        "\n",
        "La librería de scikit-learn nos proporciona una implementación que nos permite aplicar la técnica de GridSearch con nuestros modelos para poder obtener de forma fácil los hiperparámetros optimos para nuestros problemas. \n",
        "\n",
        "Buscando en la documentación de scikit-learn del modelo o modelos para los que queremos encontrar los hiperparámetros óptimos, debemos seleccionar qué hiperparámetros son los que vamos a optimizar, todos o un subconjunto de los hiperparámetros disponibles del modelo. \n",
        "\n",
        "Una vez hemos decidido qué hiperparámetros vamos a optimizar, tenemos que crear un diccionario con el nombre del hiperparámetro como clave y un array de valores que queremos probar para cada hiperparámetro como valor del diccionario. Este es el elemento clave que nos permite ir probando distintas combinaciones de hiperparámetros. Cuantos más valores añadamos para probar, mayor será el número de combinaciones disponibles y por lo tanto mayor será el tiempo que se necesite para la obtención de la mejor combinación de hiperparámetros. \n",
        "\n",
        "Vamos a ver un ejemplo de aplicación de GridSearch: \n",
        "\n"
      ],
      "metadata": {
        "id": "8_263e4cpOmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd  \n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "zi_otrMhmOhT"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vamos a cargar los datos que vamos a utilizar, del set de datos relacionados con el Titanic\n",
        "df = pd.read_csv('train_titanic.csv', index_col=0)\n",
        "\n",
        "# Separamos nuestros datos entre la columna objetivo y el resto de columnas que utilizaremos en nuestro modelo\n",
        "y= df.Survived\n",
        "features = df.drop(columns=['Survived'],axis=1)"
      ],
      "metadata": {
        "id": "xAOz2teIrfc2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a preparar rápidamente nuestros datos para poder utilizarlos en el modelo\n",
        "# vamos a eliminar las columnas que no nos interesen\n",
        "features = features.drop(columns=['Cabin','Name','Ticket'], axis=1)\n",
        "\n",
        "# Transformamos las variables categóricas en numéricas \n",
        "X = pd.get_dummies(features)\n",
        "\n",
        "# Rellenamos los valores vacíos con un valor de cero\n",
        "X = X.fillna(0)"
      ],
      "metadata": {
        "id": "RJHcglFgsOsK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a crear una instancia de nuestro modelo, en este caso el random forest \n",
        "# Optamos por los hiperparámetros por defecto para poder comparar los resultados que nos ofrece\n",
        "# el modelo con los valores óptimos que encontremos de nuestros hiperparámetros\n",
        "rf = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "McCX5xB7tLSt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separamos nuestros datos en set entrenamiento y de pruebas siguiendo un enfoque de \n",
        "# validación simple\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
      ],
      "metadata": {
        "id": "PtIhcw4ntlR9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# entrenamos nuestro modelo con los datos del set de entrenamiento\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZ-4OM71uBjh",
        "outputId": "77b87f7c-477e-4d80-b3f2-9ef77686b9be"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Y calculamos la precisión de clasificación del modelo \n",
        "precision_defecto = rf.score(X_test, y_test)\n",
        "precision_defecto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHsUZRBpuHEn",
        "outputId": "bb0ec0e0-e0bb-4ef8-e0cc-2d0ebd69a965"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8156424581005587"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ahora vamos a empezar a crear nuestro diccionario de hiperparámetros que vamos\n",
        "# a probar para buscar la mejor combinación. \n",
        "\n",
        "n_estimators = [10, 100, 1000]\n",
        "max_features = ['sqrt','log2']\n",
        "criterion = ['gini', 'entropy','log_loss']\n",
        "\n",
        "rf_grid = {'n_estimators':n_estimators, 'max_features':max_features, 'criterion':criterion}"
      ],
      "metadata": {
        "id": "zdjvRPAbucuj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos encontrar la lista completa de los hiperparámetros del modelo de random forest en la documentación oficial de scikit-learn en el siguiente [link](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
      ],
      "metadata": {
        "id": "lkf5Pf8KvMhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vamos a crear un objeto que nos permita aplicar la técnica de grid search para nuestro modelo\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=rf_grid)"
      ],
      "metadata": {
        "id": "6k0WRAMpvHs3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# el resultado de GridSearch nos da el modelo optimo y por lo tanto podemos entrenarlo\n",
        "# y obtener el valor de precisión de clasificación de nuestro modelo con hiperparámetros óptimos\n",
        "\n",
        "grid_search_rf = grid_search.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "erXlS8oQvu5t"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Una vez ha encontrado los mejore valores para los hiperparámetros de nuestro modelo\n",
        "# podemos ver esos valores\n",
        "\n",
        "grid_search_rf.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvFgi1OdwTe7",
        "outputId": "fbfc547d-9280-4879-d040-cb7427cef8a9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculamos la precisión de clasificación de nuestro modelo con los hiperparámetros óptimos\n",
        "precision_gridsearch = grid_search_rf.score(X_test,y_test)\n",
        "precision_gridsearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBk7AVfhwsJ8",
        "outputId": "b4201be6-538e-4ac7-8808-e395a46864c1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8100558659217877"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La precisión del modelo se ve modificada al variar los valores de los hiperparámetros. Podemos seguir explorando con otros valores y otros hiperparámetros para conseguir una mejora en la precisión del modelo. "
      ],
      "metadata": {
        "id": "fehYgUvzxRBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RandomSearch\n",
        "\n",
        "Dado que la aplicación de la técnica de GridSearch puede consumir grandes cantidades de recursos computacionales dependiendo del tamaño del set de datos y el número de combinaciones que queremos realizar, los científicos de datos buscaron otra alternativa que fuese más rápida. Trabajaron en la técnica de RandomSearch, que se basa en muestrear al azar a partir de una varieddad de parámetros los valores que queremos dar a los hiperparámetros de nuestro modelo. La idea principal detrás de está técnica es que se puede cubrir el conjunto de parámetros óptimos más rápido que utilizando el GridSearch. Esta técnica,sin embargo, es considerada ingenua (naive), puesto que no sabe ni recuerdad nada de sus ejecuciones anteriores. \n",
        "\n",
        "La librería de scikit-learn nos proporciona una implementación que nos permite aplicar la técnica de RandomSearch con nuestros modelos para poder obtener de forma fácil los hiperparámetros optimos para nuestros problemas.\n",
        "\n",
        "Al igual que con la técnica de GridSearch, debemos crear un diccionario con los valores que queremos poder probar para cada uno de los hiperparámetros que queremos optimizar y luego utilizar dicho diccionario en el proceso de optimización. \n",
        "\n",
        "Vamos a ver, siguiendo con el ejemplo anterior, como aplicar RandomSearch: "
      ],
      "metadata": {
        "id": "CnrdThKCxj5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "metadata": {
        "id": "-ERbyOAdxC9i"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creamos el objeto que nos permite aplicar la técnica de RandomSearch\n",
        "random_search = RandomizedSearchCV(rf, param_distributions=rf_grid)"
      ],
      "metadata": {
        "id": "cPaD6HRNzncJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicamos la técnica de RandomSearch para conseguir los valores óptimos de los \n",
        "# hiperparámetros para nuestro modelo y entrenamos el mejor modelo con nuestros datos\n",
        "\n",
        "random_search_rf = random_search.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "o8jvyzC0z09P"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Una vez ha encontrado los mejore valores para los hiperparámetros de nuestro modelo\n",
        "# podemos ver esos valores\n",
        "\n",
        "random_search_rf.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrT7aBUu0FyQ",
        "outputId": "984fbee3-70ed-40fe-a27d-4dc493f75b09"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculamos la precisión de clasificación de nuestro modelo con los hiperparámetros óptimos\n",
        "precision_randomsearch = random_search_rf.score(X_test,y_test)\n",
        "precision_randomsearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRhSQiBT0L7j",
        "outputId": "bf07373e-1569-4086-b17f-01ec46190e11"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.770949720670391"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso, vemos que la precisión del modelo se ha visto afectada por la aplicación de la técnica de RandomSearch, pero siempre podemos modificar el diccionario de valores que queremos probar para cada hiperparámetro y añadir otros hiperparámetros para poder conseguir un mejor rendimiento de nuestro modelo. "
      ],
      "metadata": {
        "id": "uIvp0uRf0d20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimización bayesiana de hiperparámetros\n",
        "\n",
        "La técnica de optimización bayesiana se basa en buscar el valor minimo para una función objetivo, construyendo a su vez una distribución de probabilidades de los valores de esa función. La optimización de esa distribución de probabilidad es más fácil a nivel computacional que la optimización de la función original. \n",
        "\n",
        "La diferencia entre la optimización bayesiana y las técnicas como GridSearch y RandomSearch es que la optimización bayesiana utiliza los resultados del pasado para seleccionar cuales van a ser los siguientes valores a evaluar. \n",
        "\n",
        "En la optimización bayesiana de hiperparámetros de modelos de machine learning, la función objetivo es el error de validación del modelo utilizando un set de hiperparámetros. El objetivo de esta técnica es encontrar los valores de los hiperparámetros que generan un valor mínimo del error de validación, esperando que esos hiperparámetros generen también un valor mínimo del error en el set de pruebas. \n",
        "\n",
        "Evaluar la función objetivo es computacionalmente caro puesto que necesitas entrenar el modelo con un set de hiperparámetros. Idealmente, queremos una técnica que nos permite explorar el espacio de valores mientras que limitamos el número de evaluaciones del error de validación con malas combinaciones de hiperparámetros. La técnica de optimización bayesiana utiliza una distribución de probabilidades que se \"concentra\" en los hiperparámetros que presentan mejores perspectivas basándose en los resultados de las evaluaciones pasadas. "
      ],
      "metadata": {
        "id": "2pQWBXRv052A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a seguir con el ejemplo anterior, utilizando ahora la técnica de optimización bayesiana de los hiperparámetros de nuestro modelo"
      ],
      "metadata": {
        "id": "2j2fDPah3pMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from hyperopt import STATUS_OK, tpe, hp, Trials\n",
        "from hyperopt.fmin import fmin\n",
        "from timeit import default_timer as timer\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "mFsx4I970SbK"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_EVALS = 500\n",
        "N_FOLDS= 10\n",
        "seed = 123"
      ],
      "metadata": {
        "id": "pncycQ2T3wc8"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos nuestra función objetivo que buscará la optimización de nuestro modelo de \n",
        "# random forest utilizando los hiperparámetros que queremos optimizar\n",
        "def objective(params):\n",
        "    est=int(params['n_estimators'])\n",
        "    md=int(params['max_depth'])\n",
        "    msl=int(params['min_samples_leaf'])\n",
        "    mss=int(params['min_samples_split'])\n",
        "    model=RandomForestClassifier(n_estimators=est,max_depth=md,min_samples_leaf=msl,min_samples_split=mss)\n",
        "    model.fit(X_train,y_train)\n",
        "    pred=model.predict(X_test)\n",
        "    score=mean_squared_error(y_test,pred)\n",
        "    return score"
      ],
      "metadata": {
        "id": "RbXY8_qq31ja"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Esta función nos permite definir el espacio de los valores que pueden tomar los hiperparámetros \n",
        "# que vamos a optimizar. Además cuando escoge los valores que vamos a probar para nuestros hiperparámetros\n",
        "# calcula el valor de la función objetivo y busca el valor óptimo para minimizar el resultado de esa \n",
        "# función objetivo\n",
        "def optimize(trial):\n",
        "    params={'n_estimators':hp.uniform('n_estimators',100,500),\n",
        "           'max_depth':hp.uniform('max_depth',5,20),\n",
        "           'min_samples_leaf':hp.uniform('min_samples_leaf',1,5),\n",
        "           'min_samples_split':hp.uniform('min_samples_split',2,6)}\n",
        "    best=fmin(fn=objective,space=params,algo=tpe.suggest,trials=trial,max_evals=500,rstate=np.random.RandomState(seed))\n",
        "    return best"
      ],
      "metadata": {
        "id": "wX0sOOz55TXu"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finalmente lanzamos el proceso de optimización.\n",
        "trial=Trials()\n",
        "best=optimize(trial)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZqHL6ZT6YGI",
        "outputId": "0fe3364d-2444-4625-e207-a47718b352be"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 500/500 [05:32<00:00,  1.51it/s, best loss: 0.12849162011173185]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# podemos ver cuales son los mejores valores de los hiperparámetros que hemos conseguido con el proceso de \n",
        "# optimización bayesiana\n",
        "print(best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQUbyaBr6bp1",
        "outputId": "2a5809b3-fa51-411f-b132-dfc8b79bdccb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 8.979353900393882, 'min_samples_leaf': 1.5188500441640422, 'min_samples_split': 2.4685823620647405, 'n_estimators': 102.79481832266357}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el modelo con los valores óptimos para los hiperparámetros que hemos encontrado\n",
        "# tomamos los valores enteros más cercanos a los valores obtenidos puesto que los hiperparámetros\n",
        "# esperan tener valores enteros\n",
        "rf_bayesiano = RandomForestClassifier(max_depth=9,\n",
        "                                      min_samples_leaf=2, \n",
        "                                      min_samples_split=3,\n",
        "                                      n_estimators=103)"
      ],
      "metadata": {
        "id": "u0waO31u7uR5"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#entrenamos el modelo con el set de entrenamiento\n",
        "rf_bayesiano.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJzHxOb48T09",
        "outputId": "0e2e10f1-829b-4fbc-b994-07ef02afae8b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=9, min_samples_leaf=2, min_samples_split=3,\n",
              "                       n_estimators=103)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculamos la precisión de clasificación del modelo óptimo\n",
        "precision_bayesiano = rf_bayesiano.score(X_test, y_test)\n",
        "precision_bayesiano"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ukYfKLg8h42",
        "outputId": "eaa5a607-29c9-405a-a061-1ceaf728c163"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8659217877094972"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7d8COej280dU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}